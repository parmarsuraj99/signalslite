{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from concurrent import futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from src.config import DAILY_DATA_DIR, DATA_DIR\n",
    "from src.data_utils import load_recent_data_from_file, save_daily_data, get_latest_date, save_in_folders\n",
    "from credentials import EODHD_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "#logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eodhd_api_key = EODHD_API_KEY\n",
    "os.environ[\"EODHD_API_KEY\"] = eodhd_api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download raw data - save merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataDownloader:\n",
    "    def __init__(self, data_dir=\"data\", max_workers=8):\n",
    "        self.max_workers = max_workers\n",
    "        self.data_dir = Path(data_dir)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dividends_eodhd(ticker, api_key, date_from):\n",
    "        \"\"\"\n",
    "        Load the splits data from the EOD Historical Data API.\n",
    "        \"\"\"\n",
    "        url = f\"https://eodhistoricaldata.com/api/div/{ticker}?api_token={api_key}&fmt=json&from={date_from}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if len(response.json()) > 0:\n",
    "                res = (\n",
    "                    pd.DataFrame(response.json())\n",
    "                    .set_index(\"date\")\n",
    "                    .add_prefix(\"dividend_\")\n",
    "                )\n",
    "                res.index = pd.to_datetime(res.index, format=\"%Y-%m-%d\")\n",
    "                res.rename(columns={\"dividend_value\": \"dividend_amount\"}, inplace=True)\n",
    "                # keep only the dividend amount and date\n",
    "                res = res[[\"dividend_amount\"]]\n",
    "                return res\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_splits_eodhd(ticker, api_key, date_from):\n",
    "        \"\"\"\n",
    "        Load the splits data from the EOD Historical Data API.\n",
    "        \"\"\"\n",
    "        url = f\"https://eodhistoricaldata.com/api/splits/{ticker}?api_token={api_key}&fmt=json&from={date_from}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if len(response.json()) > 0:\n",
    "                df = (\n",
    "                    pd.DataFrame(response.json())\n",
    "                    .set_index(\"date\")\n",
    "                    .rename(columns={\"split\": \"split_ratio\"})\n",
    "                )\n",
    "                # parse the split ratio from string to float: '2.000000/1.000000' -> 2.0\n",
    "                df[\"split_ratio\"] = df[\"split_ratio\"].apply(\n",
    "                    lambda x: float(x.split(\"/\")[0])\n",
    "                )\n",
    "                df.index = pd.to_datetime(df.index, format=\"%Y-%m-%d\")\n",
    "                return df\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def download_splits_yahoo(ticker, start_date, end_date):\n",
    "        start_epoch = int(start_date.timestamp())\n",
    "        end_epoch = int(end_date.timestamp())\n",
    "\n",
    "        splits = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=split&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if splits is not None and len(splits) > 1:\n",
    "            splits[\"date64\"] = pd.to_datetime(splits.index, format=\"%Y-%m-%d\")\n",
    "            splits = (\n",
    "                splits.reset_index(drop=True)\n",
    "                .set_index(\"date64\")\n",
    "                .sort_index()\n",
    "                .rename(columns={\"Stock Splits\": \"split_factor\"})\n",
    "            )\n",
    "\n",
    "        return splits\n",
    "\n",
    "    @staticmethod\n",
    "    def download_dividends_yahoo(ticker, start_date, end_date):\n",
    "        start_epoch = int(start_date.timestamp())\n",
    "        end_epoch = int(end_date.timestamp())\n",
    "\n",
    "        dividends = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=div&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if dividends is not None and len(dividends) > 1:\n",
    "            dividends[\"date64\"] = pd.to_datetime(dividends.index, format=\"%Y-%m-%d\")\n",
    "            dividends = (\n",
    "                dividends.reset_index(drop=True)\n",
    "                .set_index(\"date64\")\n",
    "                .sort_index()\n",
    "                .rename(columns={\"Dividends\": \"dividend_amount\"})\n",
    "            )\n",
    "\n",
    "        return dividends\n",
    "\n",
    "    def yahoo_download_one(self, signals_ticker, date_from=None, date_until=None):\n",
    "        if date_from is None:\n",
    "            date_from = \"2000-01-01\"\n",
    "        if date_until is None:\n",
    "            date_until = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        date_from = datetime.strptime(date_from, \"%Y-%m-%d\")\n",
    "        date_until = datetime.strptime(date_until, \"%Y-%m-%d\")\n",
    "\n",
    "        start_epoch = int(date_from.timestamp())\n",
    "        end_epoch = int(date_until.timestamp())\n",
    "\n",
    "        quotes = None\n",
    "\n",
    "        quotes = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{signals_ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if quotes is not None and len(quotes) > 1:\n",
    "            quotes[\"date64\"] = pd.to_datetime(quotes.index, format=\"%Y-%m-%d\")\n",
    "            quotes = quotes.reset_index(drop=True).set_index(\"date64\").sort_index()\n",
    "            quotes.index.name = \"date\"\n",
    "            quotes.columns = [\n",
    "                \"open\",\n",
    "                \"high\",\n",
    "                \"low\",\n",
    "                \"close\",\n",
    "                \"adjusted_close\",\n",
    "                \"volume\",\n",
    "            ]\n",
    "\n",
    "            dividends = StockDataDownloader.download_dividends_yahoo(\n",
    "                signals_ticker, date_from, date_until\n",
    "            )\n",
    "            splits = StockDataDownloader.download_splits_yahoo(\n",
    "                signals_ticker, date_from, date_until\n",
    "            )\n",
    "\n",
    "            if dividends is not None and len(dividends) > 1:\n",
    "                quotes = quotes.join(dividends, how=\"left\")\n",
    "\n",
    "            if splits is not None and len(splits) > 1:\n",
    "                quotes = quotes.join(splits, how=\"left\")\n",
    "\n",
    "        return quotes\n",
    "\n",
    "    def eodhd_download_one(\n",
    "        self, signals_ticker, api_key, date_from=None, date_until=None\n",
    "    ):\n",
    "        if date_from is None:\n",
    "            start_date = \"2000-01-01\"\n",
    "        else:\n",
    "            start_date = date_from\n",
    "\n",
    "        quotes = None\n",
    "\n",
    "        r = requests.get(\n",
    "            f\"https://eodhistoricaldata.com/api/eod/{signals_ticker}?from={start_date}&fmt=json&api_token={api_key}\"\n",
    "        )\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            if len(r.json()) > 0:\n",
    "                quotes = pd.DataFrame(r.json()).set_index(\"date\")\n",
    "                quotes[\"date64\"] = pd.to_datetime(quotes.index, format=\"%Y-%m-%d\")\n",
    "                quotes = quotes.reset_index(drop=True).set_index(\"date64\").sort_index()\n",
    "                quotes.index.name = \"date\"\n",
    "                quotes.columns = [\n",
    "                    \"open\",\n",
    "                    \"high\",\n",
    "                    \"low\",\n",
    "                    \"close\",\n",
    "                    \"adjusted_close\",\n",
    "                    \"volume\",\n",
    "                ]\n",
    "\n",
    "            dividends = StockDataDownloader.load_dividends_eodhd(\n",
    "                signals_ticker, api_key, date_from\n",
    "            )\n",
    "            splits = StockDataDownloader.load_splits_eodhd(\n",
    "                signals_ticker, api_key, date_from\n",
    "            )\n",
    "            \n",
    "            if dividends is not None:\n",
    "                quotes: pd.DataFrame = quotes.join(dividends, how=\"left\", on=\"date\")\n",
    "\n",
    "            if splits is not None:\n",
    "                quotes: pd.DataFrame = quotes.join(splits, how=\"left\", on=\"date\")\n",
    "\n",
    "        return quotes\n",
    "\n",
    "    def download_one(self, bloomberg_ticker, map, eodhd_api_key=None, date_from=None):\n",
    "        yahoo_ticker = map.loc[bloomberg_ticker, \"yahoo\"]\n",
    "        signals_ticker = map.loc[bloomberg_ticker, \"signals_ticker\"]\n",
    "        data_provider = map.loc[bloomberg_ticker, \"data_provider\"]\n",
    "\n",
    "        if pd.isnull(signals_ticker):\n",
    "            return bloomberg_ticker, None\n",
    "\n",
    "        quotes = None\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                if data_provider == \"eodhd\":\n",
    "                    quotes = self.eodhd_download_one(\n",
    "                        signals_ticker, eodhd_api_key, date_from=date_from\n",
    "                    )\n",
    "                elif data_provider == \"yahoo\":\n",
    "                    quotes = self.yahoo_download_one(\n",
    "                        signals_ticker=signals_ticker, date_from=date_from\n",
    "                    )\n",
    "\n",
    "                if quotes is not None:\n",
    "                    quotes[\"data_provider\"] = data_provider\n",
    "                    \n",
    "                break\n",
    "\n",
    "            except Exception as ex:\n",
    "\n",
    "                #logger.exception(ex)\n",
    "\n",
    "                print(\n",
    "                    f\"download_one, ticker:{signals_ticker}, data provider: {data_provider}, exception:{ex}, bbg_ticker:{bloomberg_ticker}\"\n",
    "                )\n",
    "                time.sleep(5)\n",
    "\n",
    "        return bloomberg_ticker, quotes\n",
    "\n",
    "    def download_all(self, ticker_map, eodhd_api_key, date_from=None):\n",
    "        tickers = pd.Series(ticker_map.index).sample(frac=1).unique().tolist()\n",
    "        print(f\"download_all, tickers:{len(tickers)}\")\n",
    "\n",
    "        all_quotes = []\n",
    "\n",
    "        with futures.ThreadPoolExecutor(self.max_workers) as executor:\n",
    "            _futures = []\n",
    "            for ticker in tqdm(tickers):\n",
    "                _futures.append(\n",
    "                    executor.submit(\n",
    "                        self.download_one,\n",
    "                        bloomberg_ticker=ticker,\n",
    "                        map=ticker_map,\n",
    "                        eodhd_api_key=eodhd_api_key,\n",
    "                        date_from=date_from,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print(f\"download_all, futures:{len(_futures)}\")\n",
    "            for future in tqdm(futures.as_completed(_futures), total=len(tickers)):\n",
    "                bloomberg_ticker, quotes = future.result()\n",
    "                if quotes is not None:\n",
    "                    quotes[\"bloomberg_ticker\"] = bloomberg_ticker\n",
    "                    all_quotes.append(quotes)\n",
    "\n",
    "        return all_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_rows(df):\n",
    "    df = df[df[\"open\"] > 0]\n",
    "    df = df[df[\"high\"] > 0]\n",
    "    df = df[df[\"low\"] > 0]\n",
    "    df = df[df[\"close\"] > 0]\n",
    "    df = df[df[\"adjusted_close\"] > 0]\n",
    "    df = df[df[\"volume\"] > 0]\n",
    "    return df\n",
    "\n",
    "def re_adjust_ohlc(df):\n",
    "    ratio = df[\"close\"] / df[\"adjusted_close\"]\n",
    "    df[\"open\"] = df[\"open\"] / ratio\n",
    "    df[\"high\"] = df[\"high\"] / ratio\n",
    "    df[\"low\"] = df[\"low\"] / ratio\n",
    "    df[\"close\"] = df[\"close\"] / ratio\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest date: 2023-06-30\n",
      "download_all, tickers:13574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13574/13574 [00:00<00:00, 25794.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_all, futures:13574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1629/13574 [01:56<06:57, 28.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:6641.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:6641 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1756/13574 [02:01<12:16, 16.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:6641.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:6641 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1816/13574 [02:06<09:07, 21.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:6641.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:6641 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3451/13574 [04:10<14:15, 11.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:5486.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:5486 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 3526/13574 [04:15<09:16, 18.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:5486.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:5486 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 3593/13574 [04:21<10:03, 16.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:5486.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:5486 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4586/13574 [05:34<12:56, 11.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:STM.PA, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:STM FP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4663/13574 [05:41<13:42, 10.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:STM.PA, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:STM FP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 4749/13574 [05:47<10:12, 14.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:STM.PA, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:STM FP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5139/13574 [06:15<11:57, 11.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:9086.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:9086 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 5207/13574 [06:20<07:46, 17.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:9086.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:9086 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 5271/13574 [06:26<12:06, 11.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:9086.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:9086 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 6325/13574 [07:45<09:03, 13.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:AUD.US, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:AUD US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 6409/13574 [07:52<07:54, 15.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:AUD.US, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:AUD US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 6486/13574 [07:58<11:54,  9.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:AUD.US, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:AUD US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 8957/13574 [11:08<04:22, 17.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:8385.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:8385 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 9022/13574 [11:13<04:58, 15.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:8385.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:8385 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 9080/13574 [11:18<05:00, 14.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:8385.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:8385 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 10060/13574 [12:34<03:44, 15.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:3966.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:3966 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 10125/13574 [12:39<03:54, 14.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:3966.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:3966 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 10191/13574 [12:45<04:43, 11.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:3966.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:3966 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 11083/13574 [13:53<03:05, 13.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:ZEL.NZ, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:ZEL NZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 11149/13574 [13:58<02:32, 15.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:ZEL.NZ, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:ZEL NZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 11214/13574 [14:03<03:26, 11.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:ZEL.NZ, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:ZEL NZ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 11668/13574 [14:38<02:03, 15.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:9375.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:9375 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▋ | 11728/13574 [14:43<03:29,  8.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:9375.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:9375 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 11792/13574 [14:49<02:57, 10.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:9375.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:9375 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 12395/13574 [15:35<01:59,  9.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:PKI.US, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:PKI US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12477/13574 [15:41<01:24, 12.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:PKI.US, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:PKI US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 12561/13574 [15:48<01:18, 12.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:PKI.US, data provider: eodhd, exception:'NoneType' object has no attribute 'join', bbg_ticker:PKI US\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▎| 12692/13574 [15:57<00:51, 17.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:8355.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:8355 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 12749/13574 [16:03<01:16, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:8355.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:8355 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 12810/13574 [16:08<01:10, 10.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:8355.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:8355 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 13464/13574 [16:59<00:08, 13.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:4541.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:4541 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13516/13574 [17:04<00:07,  8.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:4541.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:4541 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 13572/13574 [17:09<00:00,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download_one, ticker:4541.T, data provider: yahoo, exception:HTTP Error 404: Not Found, bbg_ticker:4541 JP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13574/13574 [17:14<00:00, 13.12it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 330.39it/s]\n"
     ]
    }
   ],
   "source": [
    "def update_daily_data(data_dir:str, daily_data_dir: str):\n",
    "    # read the latest date\n",
    "    latest_date = get_latest_date(daily_data_dir)\n",
    "    print(f\"Latest date: {latest_date}\")\n",
    "\n",
    "    # download data from the latest date\n",
    "    downloader = StockDataDownloader(data_dir=data_dir, max_workers=16)\n",
    "\n",
    "    ticker_map = pd.read_csv(\"data/eodhd-map.csv\").set_index(\"bloomberg_ticker\")\n",
    "    eodhd_api_key = os.environ[\"EODHD_API_KEY\"]\n",
    "    all_quotes = downloader.download_all(\n",
    "       ticker_map, eodhd_api_key, date_from=latest_date\n",
    "    )\n",
    "\n",
    "    # save all quotes\n",
    "    all_quotes = pd.concat(all_quotes)\n",
    "    all_quotes = remove_wrong_rows(all_quotes)\n",
    "    all_quotes = re_adjust_ohlc(all_quotes)\n",
    "    save_in_folders(all_quotes, daily_data_dir)\n",
    "    gc.collect()\n",
    "\n",
    "update_daily_data(DATA_DIR, DAILY_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
