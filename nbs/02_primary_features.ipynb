{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cudf\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "from signalslite.data_utils import load_recent_data_from_file, save_in_folders, get_latest_date, read_available_dates\n",
    "from signalslite.constants import Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_config = Directories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from signalslite.technical_features import (\n",
    "    simple_moving_average,\n",
    "    exponential_moving_average,\n",
    "    bollinger_bands,\n",
    "    rsi,\n",
    "    macd,\n",
    "    average_true_range,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DAILY_DATA_DIR = \"..\" / DAILY_DATA_DIR\n",
    "DAILY_PRIMARY_FEATURES_DIR = \"..\" / DAILY_PRIMARY_FEATURES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DAILY_PRIMARY_FEATURES_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m n_days_to_load \u001b[39m=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m# if some of secondary features in days are there then take last 1000 days in adjusted data: 1000\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# else take all days in adjusted data: -1\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(DAILY_PRIMARY_FEATURES_DIR):\n\u001b[1;32m      6\u001b[0m     dates \u001b[39m=\u001b[39m read_available_dates(DAILY_PRIMARY_FEATURES_DIR)\n\u001b[1;32m      7\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(dates) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DAILY_PRIMARY_FEATURES_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "n_days_to_load = -1\n",
    "\n",
    "# if some of secondary features in days are there then take last 1000 days in adjusted data: 1000\n",
    "# else take all days in adjusted data: -1\n",
    "if os.path.exists(DAILY_PRIMARY_FEATURES_DIR):\n",
    "    dates = read_available_dates(DAILY_PRIMARY_FEATURES_DIR)\n",
    "    if len(dates) > 0:\n",
    "        n_days_to_load = 1000\n",
    "\n",
    "print(f\"n_days_to_load: {n_days_to_load}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6557330 entries, 6566927 to 4088\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   date              datetime64[ns]\n",
      " 1   open              float16       \n",
      " 2   high              float16       \n",
      " 3   low               float16       \n",
      " 4   close             float16       \n",
      " 5   adjusted_close    float16       \n",
      " 6   volume            float64       \n",
      " 7   data_provider     object        \n",
      " 8   bloomberg_ticker  object        \n",
      " 9   dividend_amount   float16       \n",
      " 10  split_ratio       float16       \n",
      " 11  date_str          object        \n",
      " 12  split_factor      object        \n",
      "dtypes: datetime64[ns](1), float16(7), float64(1), object(4)\n",
      "memory usage: 437.7+ MB\n"
     ]
    }
   ],
   "source": [
    "recent_data = load_recent_data_from_file(DAILY_DATA_DIR, n_days=n_days_to_load, ascending=False).reset_index().sort_values(\n",
    "    by=[\"bloomberg_ticker\", \"date\"]\n",
    ")\n",
    "\n",
    "recent_data[\n",
    "    [\"open\", \"close\", \"high\", \"low\", \"adjusted_close\", \"dividend_amount\", \"split_ratio\"]\n",
    "] = recent_data[\n",
    "    [\"open\", \"close\", \"high\", \"low\", \"adjusted_close\", \"dividend_amount\", \"split_ratio\"]\n",
    "].astype(\n",
    "    \"float16\"\n",
    ")\n",
    "\n",
    "# filter out tickers with less than 100 days of data\n",
    "recent_data = recent_data.groupby(\"bloomberg_ticker\").filter(lambda x: len(x) > 100)\n",
    "recent_data = recent_data.groupby(\"date\").filter(lambda x: len(x) > 500)\n",
    "gc.collect()\n",
    "\n",
    "recent_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "function_to_window: dict = {\n",
    "    simple_moving_average: [5, 10, 20, 50, 100, 200],\n",
    "    exponential_moving_average: [5, 10, 20, 50, 100, 200],\n",
    "    bollinger_bands: [5, 10, 20, 50, 100, 200],\n",
    "    rsi: [5, 10, 20, 50, 100, 200],\n",
    "    average_true_range: [5, 10, 20, 50, 100, 200],\n",
    "    macd: [(12, 26), (20, 50)],\n",
    "}\n",
    "\n",
    "\n",
    "def compute_features(df):\n",
    "    features = []\n",
    "    for func, windows in function_to_window.items():\n",
    "        for window in windows:\n",
    "            # pass windows as a tuple if the function takes more than one window\n",
    "            if isinstance(window, tuple):\n",
    "                _feat = func(df, *window)\n",
    "            else:\n",
    "                _feat = func(df, window)\n",
    "\n",
    "            if isinstance(_feat, tuple):\n",
    "                features.extend(_feat)\n",
    "            else:\n",
    "                features.append(_feat)\n",
    "\n",
    "    # print type of features\n",
    "    cated = cudf.concat(features, axis=1).astype(\"float32\").add_prefix(\"feature_1_\")\n",
    "    return cated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:14<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "tickers_list = recent_data[\"bloomberg_ticker\"].unique().tolist()\n",
    "\n",
    "# iterate over ticker chunks in 500\n",
    "res = []\n",
    "for i in tqdm(range(0, len(tickers_list), 1000)):\n",
    "    tickers = tickers_list[i : i + 1000]\n",
    "    # print(tickers)\n",
    "    tickers_data = recent_data[recent_data[\"bloomberg_ticker\"].isin(tickers)]\n",
    "\n",
    "    _df_gpu = cudf.from_pandas(tickers_data)\n",
    "    _res = compute_features(_df_gpu)\n",
    "    _res = _res.to_pandas().astype(\"float16\")\n",
    "    _res[\"date\"] = _df_gpu[\"date\"].to_pandas()\n",
    "    _res[\"bloomberg_ticker\"] = _df_gpu[\"bloomberg_ticker\"].to_pandas()\n",
    "    _res[\"close\"] = _df_gpu[\"close\"].to_pandas()\n",
    "    _res[\"volume\"] = _df_gpu[\"volume\"].to_pandas()\n",
    "    _res[\"open\"] = _df_gpu[\"open\"].to_pandas()\n",
    "    _res[\"high\"] = _df_gpu[\"high\"].to_pandas()\n",
    "    _res[\"low\"] = _df_gpu[\"low\"].to_pandas()\n",
    "\n",
    "    res.append(_res)\n",
    "\n",
    "    del _df_gpu, _res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "res = pd.concat(res, axis=0)\n",
    "res = res.dropna(axis=0)\n",
    "\n",
    "# convert float 16 to float 32 in a loop\n",
    "for col in res.columns:\n",
    "    if res[col].dtype == \"float16\":\n",
    "        res[col] = res[col].astype(\"float32\")\n",
    "    gc.collect()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "del recent_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 55.55it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 381.64it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 395.25it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 365.26it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 349.17it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 393.26it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 382.34it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 394.20it/s]\n",
      "100%|██████████| 40/40 [00:00<00:00, 900.74it/s]\n",
      "100%|██████████| 9/9 [00:11<00:00,  1.23s/it]\n"
     ]
    }
   ],
   "source": [
    "# loop over all unique dates in chunks of 100; save each chunk to a separate file\n",
    "res[\"date_str\"] = res[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "dates = res[\"date_str\"].unique()\n",
    "\n",
    "for i in tqdm(range(0, len(dates), 100)):\n",
    "    # use save_in_folders function to save each chunk to a separate folder\n",
    "    _tmp = res[res[\"date_str\"].isin(dates[i : i + 100])]\n",
    "    save_in_folders(_tmp, DAILY_PRIMARY_FEATURES_DIR)\n",
    "\n",
    "    del _tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tmp = pd.read_parquet(\"/mnt/d/nmr/signalslite/data/01_daily_adjusted/2005/03/2005-03-01.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
