{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cudf\n",
    "import numba\n",
    "from numba import cuda\n",
    "import numpy as np\n",
    "import numerapi\n",
    "\n",
    "# parallelize the process on all columns using joblib\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from signalslite.data_utils import (\n",
    "    load_recent_data_from_file,\n",
    "    save_daily_data,\n",
    "    save_in_folders,\n",
    "    get_latest_date,\n",
    "    read_available_dates\n",
    ")\n",
    "from signalslite.constants import Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_historical_file(dir_config):\n",
    "    napi = numerapi.SignalsAPI(verbosity=\"info\")\n",
    "    # get the latest date\n",
    "    pd.read_csv(napi.HISTORICAL_DATA_URL).to_csv(\n",
    "        dir_config.DATA_DIR / \"numerai_signals_historical.csv\", index=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_data(historical_df:pd.DataFrame, dir_config: Directories):\n",
    "    dates = read_available_dates(dir_config.DAILY_SCALED_FEATURES_DIR)\n",
    "\n",
    "    merged_df = []\n",
    "\n",
    "    for i in tqdm(range(0, len(dates), 200)):\n",
    "        _tmp = load_recent_data_from_file(\n",
    "            dir_config.DAILY_SCALED_FEATURES_DIR, n_days=200, ascending=True, offset=i\n",
    "        )\n",
    "        _tmp = _tmp.reset_index(drop=True)\n",
    "        _tmp = _tmp.sort_values([\"date\", \"bloomberg_ticker\"])\n",
    "        feature_columns = [f for f in _tmp.columns if f.startswith(\"feature\")]\n",
    "\n",
    "        _historical_dates = historical_df[\"date\"].unique()\n",
    "        # find common dates\n",
    "        common_dates = list(\n",
    "            set(_tmp[\"date\"].unique()).intersection(set(_historical_dates))\n",
    "        )\n",
    "\n",
    "        if len(common_dates) == 0:\n",
    "            continue\n",
    "\n",
    "        # merge historical_df and _tmp on date and bloomberg_ticker\n",
    "        _merged = pd.merge(\n",
    "            historical_df,\n",
    "            _tmp,\n",
    "            how=\"right\",\n",
    "            left_on=[\"date\", \"bloomberg_ticker\"],\n",
    "            right_on=[\"date\", \"bloomberg_ticker\"],\n",
    "        )\n",
    "        _merged = _merged.dropna(subset=[\"target_20d\"], axis=0)\n",
    "\n",
    "        # assert abs(_merged[\"feature_2_ratio_rsi_50_close\"].mean() - 2) < 0.05\n",
    "\n",
    "        if len(_merged) > 0:\n",
    "            merged_df.append(_merged)\n",
    "\n",
    "    merged_df = pd.concat(merged_df)\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [04:29<00:00,  8.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latest date:  2023-08-14\n",
      "df shape:  (727, 105)\n"
     ]
    }
   ],
   "source": [
    "def prepare_live(dir_config):\n",
    "    latest_date = get_latest_date(dir_config.DAILY_SCALED_FEATURES_DIR)\n",
    "    print(\"latest date: \", latest_date)\n",
    "    # load the latest data\n",
    "    df = load_recent_data_from_file(\n",
    "        dir_config.DAILY_SCALED_FEATURES_DIR, n_days=1, ascending=False\n",
    "    )\n",
    "    df = df.reset_index(drop=True)\n",
    "    print(\"df shape: \", df.shape)\n",
    "\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    dir_config = Directories()\n",
    "    dir_config.set_data_dir(\"../data\")\n",
    "\n",
    "    print(dir_config)\n",
    "\n",
    "    update_historical_file(dir_config)\n",
    "    historical_df = pd.read_csv(dir_config.DATA_DIR / \"numerai_signals_historical.csv\")\n",
    "    historical_df[\"date\"] = pd.to_datetime(historical_df[\"friday_date\"], format=\"%Y%m%d\")\n",
    "\n",
    "    merged_df = merge_data(historical_df, dir_config)\n",
    "    live_df = prepare_live(dir_config)\n",
    "\n",
    "    merged_df.to_parquet(dir_config.DATA_DIR / \"merged_data_historical.parquet\", index=False)\n",
    "    live_df.to_parquet(dir_config.DATA_DIR / \"merged_data_live.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
