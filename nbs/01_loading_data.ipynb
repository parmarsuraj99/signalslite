{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from concurrent import futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from signals_lite.constants import DAILY_DATA_DIR, DATA_DIR\n",
    "from signals_lite.data.data_utils import load_recent_data_from_file, save_daily_data, get_latest_date, save_in_folders\n",
    "from credentials import EODHD_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "#logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eodhd_api_key = EODHD_API_KEY\n",
    "os.environ[\"EODHD_API_KEY\"] = eodhd_api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download raw data - save merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataDownloader:\n",
    "    def __init__(self, data_dir=\"data\", max_workers=8, eodhd_apikey:str):\n",
    "        self.max_workers = max_workers\n",
    "        self.data_dir = Path(data_dir)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dividends_eodhd(ticker, api_key, date_from):\n",
    "        \"\"\"\n",
    "        Load the splits data from the EOD Historical Data API.\n",
    "        \"\"\"\n",
    "        url = f\"https://eodhistoricaldata.com/api/div/{ticker}?api_token={api_key}&fmt=json&from={date_from}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if len(response.json()) > 0:\n",
    "                res = (\n",
    "                    pd.DataFrame(response.json())\n",
    "                    .set_index(\"date\")\n",
    "                    .add_prefix(\"dividend_\")\n",
    "                )\n",
    "                res.index = pd.to_datetime(res.index, format=\"%Y-%m-%d\")\n",
    "                res.rename(columns={\"dividend_value\": \"dividend_amount\"}, inplace=True)\n",
    "                # keep only the dividend amount and date\n",
    "                res = res[[\"dividend_amount\"]]\n",
    "                return res\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_splits_eodhd(ticker, api_key, date_from):\n",
    "        \"\"\"\n",
    "        Load the splits data from the EOD Historical Data API.\n",
    "        \"\"\"\n",
    "        url = f\"https://eodhistoricaldata.com/api/splits/{ticker}?api_token={api_key}&fmt=json&from={date_from}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if len(response.json()) > 0:\n",
    "                df = (\n",
    "                    pd.DataFrame(response.json())\n",
    "                    .set_index(\"date\")\n",
    "                    .rename(columns={\"split\": \"split_ratio\"})\n",
    "                )\n",
    "                # parse the split ratio from string to float: '2.000000/1.000000' -> 2.0\n",
    "                df[\"split_ratio\"] = df[\"split_ratio\"].apply(\n",
    "                    lambda x: float(x.split(\"/\")[0])\n",
    "                )\n",
    "                df.index = pd.to_datetime(df.index, format=\"%Y-%m-%d\")\n",
    "                return df\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def download_splits_yahoo(ticker, start_date, end_date):\n",
    "        start_epoch = int(start_date.timestamp())\n",
    "        end_epoch = int(end_date.timestamp())\n",
    "\n",
    "        splits = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=split&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if splits is not None and len(splits) > 1:\n",
    "            splits[\"date64\"] = pd.to_datetime(splits.index, format=\"%Y-%m-%d\")\n",
    "            splits = (\n",
    "                splits.reset_index(drop=True)\n",
    "                .set_index(\"date64\")\n",
    "                .sort_index()\n",
    "                .rename(columns={\"Stock Splits\": \"split_factor\"})\n",
    "            )\n",
    "\n",
    "        return splits\n",
    "\n",
    "    @staticmethod\n",
    "    def download_dividends_yahoo(ticker, start_date, end_date):\n",
    "        start_epoch = int(start_date.timestamp())\n",
    "        end_epoch = int(end_date.timestamp())\n",
    "\n",
    "        dividends = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=div&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if dividends is not None and len(dividends) > 1:\n",
    "            dividends[\"date64\"] = pd.to_datetime(dividends.index, format=\"%Y-%m-%d\")\n",
    "            dividends = (\n",
    "                dividends.reset_index(drop=True)\n",
    "                .set_index(\"date64\")\n",
    "                .sort_index()\n",
    "                .rename(columns={\"Dividends\": \"dividend_amount\"})\n",
    "            )\n",
    "\n",
    "        return dividends\n",
    "\n",
    "    def yahoo_download_one(self, signals_ticker, date_from=None, date_until=None):\n",
    "        if date_from is None:\n",
    "            date_from = \"2000-01-01\"\n",
    "        if date_until is None:\n",
    "            date_until = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        date_from = datetime.strptime(date_from, \"%Y-%m-%d\")\n",
    "        date_until = datetime.strptime(date_until, \"%Y-%m-%d\")\n",
    "\n",
    "        start_epoch = int(date_from.timestamp())\n",
    "        end_epoch = int(date_until.timestamp())\n",
    "\n",
    "        quotes = None\n",
    "\n",
    "        quotes = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{signals_ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if quotes is not None and len(quotes) > 1:\n",
    "            quotes[\"date64\"] = pd.to_datetime(quotes.index, format=\"%Y-%m-%d\")\n",
    "            quotes = quotes.reset_index(drop=True).set_index(\"date64\").sort_index()\n",
    "            quotes.index.name = \"date\"\n",
    "            quotes.columns = [\n",
    "                \"open\",\n",
    "                \"high\",\n",
    "                \"low\",\n",
    "                \"close\",\n",
    "                \"adjusted_close\",\n",
    "                \"volume\",\n",
    "            ]\n",
    "\n",
    "            dividends = StockDataDownloader.download_dividends_yahoo(\n",
    "                signals_ticker, date_from, date_until\n",
    "            )\n",
    "            splits = StockDataDownloader.download_splits_yahoo(\n",
    "                signals_ticker, date_from, date_until\n",
    "            )\n",
    "\n",
    "            if dividends is not None and len(dividends) > 1:\n",
    "                quotes = quotes.join(dividends, how=\"left\")\n",
    "\n",
    "            if splits is not None and len(splits) > 1:\n",
    "                quotes = quotes.join(splits, how=\"left\")\n",
    "\n",
    "        return quotes\n",
    "\n",
    "    def eodhd_download_one(\n",
    "        self, signals_ticker, api_key, date_from=None, date_until=None\n",
    "    ):\n",
    "        if date_from is None:\n",
    "            start_date = \"2000-01-01\"\n",
    "        else:\n",
    "            start_date = date_from\n",
    "\n",
    "        quotes = None\n",
    "\n",
    "        r = requests.get(\n",
    "            f\"https://eodhistoricaldata.com/api/eod/{signals_ticker}?from={start_date}&fmt=json&api_token={api_key}\"\n",
    "        )\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            if len(r.json()) > 0:\n",
    "                quotes = pd.DataFrame(r.json()).set_index(\"date\")\n",
    "                quotes[\"date64\"] = pd.to_datetime(quotes.index, format=\"%Y-%m-%d\")\n",
    "                quotes = quotes.reset_index(drop=True).set_index(\"date64\").sort_index()\n",
    "                quotes.index.name = \"date\"\n",
    "                quotes.columns = [\n",
    "                    \"open\",\n",
    "                    \"high\",\n",
    "                    \"low\",\n",
    "                    \"close\",\n",
    "                    \"adjusted_close\",\n",
    "                    \"volume\",\n",
    "                ]\n",
    "\n",
    "            dividends = StockDataDownloader.load_dividends_eodhd(\n",
    "                signals_ticker, api_key, date_from\n",
    "            )\n",
    "            splits = StockDataDownloader.load_splits_eodhd(\n",
    "                signals_ticker, api_key, date_from\n",
    "            )\n",
    "            \n",
    "            if dividends is not None:\n",
    "                quotes: pd.DataFrame = quotes.join(dividends, how=\"left\", on=\"date\")\n",
    "\n",
    "            if splits is not None:\n",
    "                quotes: pd.DataFrame = quotes.join(splits, how=\"left\", on=\"date\")\n",
    "\n",
    "        return quotes\n",
    "\n",
    "    def download_one(self, bloomberg_ticker, map, eodhd_api_key=None, date_from=None):\n",
    "        yahoo_ticker = map.loc[bloomberg_ticker, \"yahoo\"]\n",
    "        signals_ticker = map.loc[bloomberg_ticker, \"signals_ticker\"]\n",
    "        data_provider = map.loc[bloomberg_ticker, \"data_provider\"]\n",
    "\n",
    "        if pd.isnull(signals_ticker):\n",
    "            return bloomberg_ticker, None\n",
    "\n",
    "        quotes = None\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                if data_provider == \"eodhd\":\n",
    "                    quotes = self.eodhd_download_one(\n",
    "                        signals_ticker, eodhd_api_key, date_from=date_from\n",
    "                    )\n",
    "                elif data_provider == \"yahoo\":\n",
    "                    quotes = self.yahoo_download_one(\n",
    "                        signals_ticker=signals_ticker, date_from=date_from\n",
    "                    )\n",
    "\n",
    "                if quotes is not None:\n",
    "                    quotes[\"data_provider\"] = data_provider\n",
    "                    \n",
    "                break\n",
    "\n",
    "            except Exception as ex:\n",
    "\n",
    "                #logger.exception(ex)\n",
    "\n",
    "                print(\n",
    "                    f\"download_one, ticker:{signals_ticker}, data provider: {data_provider}, exception:{ex}, bbg_ticker:{bloomberg_ticker}\"\n",
    "                )\n",
    "                time.sleep(5)\n",
    "\n",
    "        return bloomberg_ticker, quotes\n",
    "\n",
    "    def download_all(self, ticker_map, eodhd_api_key, date_from=None):\n",
    "        tickers = pd.Series(ticker_map.index).sample(frac=1).unique().tolist()\n",
    "        print(f\"download_all, tickers:{len(tickers)}\")\n",
    "\n",
    "        all_quotes = []\n",
    "\n",
    "        with futures.ThreadPoolExecutor(self.max_workers) as executor:\n",
    "            _futures = []\n",
    "            for ticker in tqdm(tickers):\n",
    "                _futures.append(\n",
    "                    executor.submit(\n",
    "                        self.download_one,\n",
    "                        bloomberg_ticker=ticker,\n",
    "                        map=ticker_map,\n",
    "                        eodhd_api_key=eodhd_api_key,\n",
    "                        date_from=date_from,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print(f\"download_all, futures:{len(_futures)}\")\n",
    "            for future in tqdm(futures.as_completed(_futures), total=len(tickers)):\n",
    "                bloomberg_ticker, quotes = future.result()\n",
    "                if quotes is not None:\n",
    "                    quotes[\"bloomberg_ticker\"] = bloomberg_ticker\n",
    "                    all_quotes.append(quotes)\n",
    "\n",
    "        return all_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_rows(df):\n",
    "    df = df[df[\"open\"] > 0]\n",
    "    df = df[df[\"high\"] > 0]\n",
    "    df = df[df[\"low\"] > 0]\n",
    "    df = df[df[\"close\"] > 0]\n",
    "    df = df[df[\"adjusted_close\"] > 0]\n",
    "    df = df[df[\"volume\"] > 0]\n",
    "    return df\n",
    "\n",
    "def re_adjust_ohlc(df):\n",
    "    ratio = df[\"close\"] / df[\"adjusted_close\"]\n",
    "    df[\"open\"] = df[\"open\"] / ratio\n",
    "    df[\"high\"] = df[\"high\"] / ratio\n",
    "    df[\"low\"] = df[\"low\"] / ratio\n",
    "    df[\"close\"] = df[\"close\"] / ratio\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_daily_data(data_dir:str, daily_data_dir: str):\n",
    "    # read the latest date\n",
    "    latest_date = get_latest_date(daily_data_dir)\n",
    "    print(f\"Latest date: {latest_date}\")\n",
    "\n",
    "    # download data from the latest date\n",
    "    downloader = StockDataDownloader(data_dir=data_dir, max_workers=16)\n",
    "\n",
    "    ticker_map = pd.read_csv(\"data/eodhd-map.csv\").set_index(\"bloomberg_ticker\")\n",
    "    eodhd_api_key = os.environ[\"EODHD_API_KEY\"]\n",
    "    all_quotes = downloader.download_all(\n",
    "       ticker_map, eodhd_api_key, date_from=latest_date\n",
    "    )\n",
    "\n",
    "    # save all quotes\n",
    "    all_quotes = pd.concat(all_quotes)\n",
    "    all_quotes = remove_wrong_rows(all_quotes)\n",
    "    all_quotes = re_adjust_ohlc(all_quotes)\n",
    "    save_in_folders(all_quotes, daily_data_dir)\n",
    "    gc.collect()\n",
    "\n",
    "update_daily_data(DATA_DIR, DAILY_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted_close</th>\n",
       "      <th>volume</th>\n",
       "      <th>data_provider</th>\n",
       "      <th>bloomberg_ticker</th>\n",
       "      <th>dividend_amount</th>\n",
       "      <th>split_ratio</th>\n",
       "      <th>date_str</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>44.900</td>\n",
       "      <td>45.520</td>\n",
       "      <td>44.580</td>\n",
       "      <td>45.010</td>\n",
       "      <td>45.010</td>\n",
       "      <td>1520155</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>TDC US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>4241.000</td>\n",
       "      <td>4267.000</td>\n",
       "      <td>4217.000</td>\n",
       "      <td>4258.000</td>\n",
       "      <td>4258.000</td>\n",
       "      <td>124369</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>BKG LN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>6.005</td>\n",
       "      <td>6.063</td>\n",
       "      <td>5.987</td>\n",
       "      <td>6.054</td>\n",
       "      <td>6.054</td>\n",
       "      <td>10389032</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>ENEL IM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>513.000</td>\n",
       "      <td>513.000</td>\n",
       "      <td>502.000</td>\n",
       "      <td>510.000</td>\n",
       "      <td>510.000</td>\n",
       "      <td>114752</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>5904 TT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>154.420</td>\n",
       "      <td>155.515</td>\n",
       "      <td>153.830</td>\n",
       "      <td>155.320</td>\n",
       "      <td>155.320</td>\n",
       "      <td>1171114</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>HLT US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>20.380</td>\n",
       "      <td>20.380</td>\n",
       "      <td>19.570</td>\n",
       "      <td>20.190</td>\n",
       "      <td>20.190</td>\n",
       "      <td>169400</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>TREE US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>7.300</td>\n",
       "      <td>7.300</td>\n",
       "      <td>7.130</td>\n",
       "      <td>7.240</td>\n",
       "      <td>7.240</td>\n",
       "      <td>1506100</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>LC US</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>11.790</td>\n",
       "      <td>11.990</td>\n",
       "      <td>11.620</td>\n",
       "      <td>11.810</td>\n",
       "      <td>11.810</td>\n",
       "      <td>3056700</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>VAMO3 BZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>3.920</td>\n",
       "      <td>3.920</td>\n",
       "      <td>3.730</td>\n",
       "      <td>3.840</td>\n",
       "      <td>3.840</td>\n",
       "      <td>182100</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>TCSA3 BZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023-08-14</th>\n",
       "      <td>23.000</td>\n",
       "      <td>23.000</td>\n",
       "      <td>22.650</td>\n",
       "      <td>22.750</td>\n",
       "      <td>22.750</td>\n",
       "      <td>7042</td>\n",
       "      <td>eodhd</td>\n",
       "      <td>FII FP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7465 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                open      high       low     close  adjusted_close    volume  \\\n",
       "date                                                                           \n",
       "2023-08-14    44.900    45.520    44.580    45.010          45.010   1520155   \n",
       "2023-08-14  4241.000  4267.000  4217.000  4258.000        4258.000    124369   \n",
       "2023-08-14     6.005     6.063     5.987     6.054           6.054  10389032   \n",
       "2023-08-14   513.000   513.000   502.000   510.000         510.000    114752   \n",
       "2023-08-14   154.420   155.515   153.830   155.320         155.320   1171114   \n",
       "...              ...       ...       ...       ...             ...       ...   \n",
       "2023-08-14    20.380    20.380    19.570    20.190          20.190    169400   \n",
       "2023-08-14     7.300     7.300     7.130     7.240           7.240   1506100   \n",
       "2023-08-14    11.790    11.990    11.620    11.810          11.810   3056700   \n",
       "2023-08-14     3.920     3.920     3.730     3.840           3.840    182100   \n",
       "2023-08-14    23.000    23.000    22.650    22.750          22.750      7042   \n",
       "\n",
       "           data_provider bloomberg_ticker  dividend_amount  split_ratio  \\\n",
       "date                                                                      \n",
       "2023-08-14         eodhd           TDC US              NaN          NaN   \n",
       "2023-08-14         eodhd           BKG LN              NaN          NaN   \n",
       "2023-08-14         eodhd          ENEL IM              NaN          NaN   \n",
       "2023-08-14         eodhd          5904 TT              NaN          NaN   \n",
       "2023-08-14         eodhd           HLT US              NaN          NaN   \n",
       "...                  ...              ...              ...          ...   \n",
       "2023-08-14         eodhd          TREE US              NaN          NaN   \n",
       "2023-08-14         eodhd            LC US              NaN          NaN   \n",
       "2023-08-14         eodhd         VAMO3 BZ              NaN          NaN   \n",
       "2023-08-14         eodhd         TCSA3 BZ              NaN          NaN   \n",
       "2023-08-14         eodhd           FII FP              NaN          NaN   \n",
       "\n",
       "              date_str  \n",
       "date                    \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "...                ...  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "2023-08-14  2023-08-14  \n",
       "\n",
       "[7465 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(\"../data/01_daily_adjusted/2023/08/2023-08-14.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
