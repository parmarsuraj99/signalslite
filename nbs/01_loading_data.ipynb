{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "from pathlib import Path\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from concurrent import futures\n",
    "from tqdm import tqdm\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "from signals_lite.constants import DAILY_DATA_DIR, DATA_DIR\n",
    "from signals_lite.data.data_utils import load_recent_data_from_file, save_daily_data, get_latest_date, save_in_folders\n",
    "from credentials import EODHD_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import logging\n",
    "#logging.basicConfig(level=logging.DEBUG)\n",
    "#logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eodhd_api_key = EODHD_API_KEY\n",
    "os.environ[\"EODHD_API_KEY\"] = eodhd_api_key"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download raw data - save merged file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StockDataDownloader:\n",
    "    def __init__(self, data_dir=\"data\", max_workers=8, eodhd_apikey:str):\n",
    "        self.max_workers = max_workers\n",
    "        self.data_dir = Path(data_dir)\n",
    "\n",
    "    @staticmethod\n",
    "    def load_dividends_eodhd(ticker, api_key, date_from):\n",
    "        \"\"\"\n",
    "        Load the splits data from the EOD Historical Data API.\n",
    "        \"\"\"\n",
    "        url = f\"https://eodhistoricaldata.com/api/div/{ticker}?api_token={api_key}&fmt=json&from={date_from}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if len(response.json()) > 0:\n",
    "                res = (\n",
    "                    pd.DataFrame(response.json())\n",
    "                    .set_index(\"date\")\n",
    "                    .add_prefix(\"dividend_\")\n",
    "                )\n",
    "                res.index = pd.to_datetime(res.index, format=\"%Y-%m-%d\")\n",
    "                res.rename(columns={\"dividend_value\": \"dividend_amount\"}, inplace=True)\n",
    "                # keep only the dividend amount and date\n",
    "                res = res[[\"dividend_amount\"]]\n",
    "                return res\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def load_splits_eodhd(ticker, api_key, date_from):\n",
    "        \"\"\"\n",
    "        Load the splits data from the EOD Historical Data API.\n",
    "        \"\"\"\n",
    "        url = f\"https://eodhistoricaldata.com/api/splits/{ticker}?api_token={api_key}&fmt=json&from={date_from}\"\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            if len(response.json()) > 0:\n",
    "                df = (\n",
    "                    pd.DataFrame(response.json())\n",
    "                    .set_index(\"date\")\n",
    "                    .rename(columns={\"split\": \"split_ratio\"})\n",
    "                )\n",
    "                # parse the split ratio from string to float: '2.000000/1.000000' -> 2.0\n",
    "                df[\"split_ratio\"] = df[\"split_ratio\"].apply(\n",
    "                    lambda x: float(x.split(\"/\")[0])\n",
    "                )\n",
    "                df.index = pd.to_datetime(df.index, format=\"%Y-%m-%d\")\n",
    "                return df\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    @staticmethod\n",
    "    def download_splits_yahoo(ticker, start_date, end_date):\n",
    "        start_epoch = int(start_date.timestamp())\n",
    "        end_epoch = int(end_date.timestamp())\n",
    "\n",
    "        splits = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=split&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if splits is not None and len(splits) > 1:\n",
    "            splits[\"date64\"] = pd.to_datetime(splits.index, format=\"%Y-%m-%d\")\n",
    "            splits = (\n",
    "                splits.reset_index(drop=True)\n",
    "                .set_index(\"date64\")\n",
    "                .sort_index()\n",
    "                .rename(columns={\"Stock Splits\": \"split_factor\"})\n",
    "            )\n",
    "\n",
    "        return splits\n",
    "\n",
    "    @staticmethod\n",
    "    def download_dividends_yahoo(ticker, start_date, end_date):\n",
    "        start_epoch = int(start_date.timestamp())\n",
    "        end_epoch = int(end_date.timestamp())\n",
    "\n",
    "        dividends = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=div&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if dividends is not None and len(dividends) > 1:\n",
    "            dividends[\"date64\"] = pd.to_datetime(dividends.index, format=\"%Y-%m-%d\")\n",
    "            dividends = (\n",
    "                dividends.reset_index(drop=True)\n",
    "                .set_index(\"date64\")\n",
    "                .sort_index()\n",
    "                .rename(columns={\"Dividends\": \"dividend_amount\"})\n",
    "            )\n",
    "\n",
    "        return dividends\n",
    "\n",
    "    def yahoo_download_one(self, signals_ticker, date_from=None, date_until=None):\n",
    "        if date_from is None:\n",
    "            date_from = \"2000-01-01\"\n",
    "        if date_until is None:\n",
    "            date_until = datetime.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "        date_from = datetime.strptime(date_from, \"%Y-%m-%d\")\n",
    "        date_until = datetime.strptime(date_until, \"%Y-%m-%d\")\n",
    "\n",
    "        start_epoch = int(date_from.timestamp())\n",
    "        end_epoch = int(date_until.timestamp())\n",
    "\n",
    "        quotes = None\n",
    "\n",
    "        quotes = (\n",
    "            pd.read_csv(\n",
    "                f\"https://query1.finance.yahoo.com/v7/finance/download/{signals_ticker}?period1={start_epoch}&period2={end_epoch}&interval=1d&events=history&includeAdjustedClose=true\"\n",
    "            )\n",
    "            .dropna()\n",
    "            .set_index(\"Date\")\n",
    "        )\n",
    "\n",
    "        if quotes is not None and len(quotes) > 1:\n",
    "            quotes[\"date64\"] = pd.to_datetime(quotes.index, format=\"%Y-%m-%d\")\n",
    "            quotes = quotes.reset_index(drop=True).set_index(\"date64\").sort_index()\n",
    "            quotes.index.name = \"date\"\n",
    "            quotes.columns = [\n",
    "                \"open\",\n",
    "                \"high\",\n",
    "                \"low\",\n",
    "                \"close\",\n",
    "                \"adjusted_close\",\n",
    "                \"volume\",\n",
    "            ]\n",
    "\n",
    "            dividends = StockDataDownloader.download_dividends_yahoo(\n",
    "                signals_ticker, date_from, date_until\n",
    "            )\n",
    "            splits = StockDataDownloader.download_splits_yahoo(\n",
    "                signals_ticker, date_from, date_until\n",
    "            )\n",
    "\n",
    "            if dividends is not None and len(dividends) > 1:\n",
    "                quotes = quotes.join(dividends, how=\"left\")\n",
    "\n",
    "            if splits is not None and len(splits) > 1:\n",
    "                quotes = quotes.join(splits, how=\"left\")\n",
    "\n",
    "        return quotes\n",
    "\n",
    "    def eodhd_download_one(\n",
    "        self, signals_ticker, api_key, date_from=None, date_until=None\n",
    "    ):\n",
    "        if date_from is None:\n",
    "            start_date = \"2000-01-01\"\n",
    "        else:\n",
    "            start_date = date_from\n",
    "\n",
    "        quotes = None\n",
    "\n",
    "        r = requests.get(\n",
    "            f\"https://eodhistoricaldata.com/api/eod/{signals_ticker}?from={start_date}&fmt=json&api_token={api_key}\"\n",
    "        )\n",
    "\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            if len(r.json()) > 0:\n",
    "                quotes = pd.DataFrame(r.json()).set_index(\"date\")\n",
    "                quotes[\"date64\"] = pd.to_datetime(quotes.index, format=\"%Y-%m-%d\")\n",
    "                quotes = quotes.reset_index(drop=True).set_index(\"date64\").sort_index()\n",
    "                quotes.index.name = \"date\"\n",
    "                quotes.columns = [\n",
    "                    \"open\",\n",
    "                    \"high\",\n",
    "                    \"low\",\n",
    "                    \"close\",\n",
    "                    \"adjusted_close\",\n",
    "                    \"volume\",\n",
    "                ]\n",
    "\n",
    "            dividends = StockDataDownloader.load_dividends_eodhd(\n",
    "                signals_ticker, api_key, date_from\n",
    "            )\n",
    "            splits = StockDataDownloader.load_splits_eodhd(\n",
    "                signals_ticker, api_key, date_from\n",
    "            )\n",
    "            \n",
    "            if dividends is not None:\n",
    "                quotes: pd.DataFrame = quotes.join(dividends, how=\"left\", on=\"date\")\n",
    "\n",
    "            if splits is not None:\n",
    "                quotes: pd.DataFrame = quotes.join(splits, how=\"left\", on=\"date\")\n",
    "\n",
    "        return quotes\n",
    "\n",
    "    def download_one(self, bloomberg_ticker, map, eodhd_api_key=None, date_from=None):\n",
    "        yahoo_ticker = map.loc[bloomberg_ticker, \"yahoo\"]\n",
    "        signals_ticker = map.loc[bloomberg_ticker, \"signals_ticker\"]\n",
    "        data_provider = map.loc[bloomberg_ticker, \"data_provider\"]\n",
    "\n",
    "        if pd.isnull(signals_ticker):\n",
    "            return bloomberg_ticker, None\n",
    "\n",
    "        quotes = None\n",
    "        for _ in range(3):\n",
    "            try:\n",
    "                if data_provider == \"eodhd\":\n",
    "                    quotes = self.eodhd_download_one(\n",
    "                        signals_ticker, eodhd_api_key, date_from=date_from\n",
    "                    )\n",
    "                elif data_provider == \"yahoo\":\n",
    "                    quotes = self.yahoo_download_one(\n",
    "                        signals_ticker=signals_ticker, date_from=date_from\n",
    "                    )\n",
    "\n",
    "                if quotes is not None:\n",
    "                    quotes[\"data_provider\"] = data_provider\n",
    "                    \n",
    "                break\n",
    "\n",
    "            except Exception as ex:\n",
    "\n",
    "                #logger.exception(ex)\n",
    "\n",
    "                print(\n",
    "                    f\"download_one, ticker:{signals_ticker}, data provider: {data_provider}, exception:{ex}, bbg_ticker:{bloomberg_ticker}\"\n",
    "                )\n",
    "                time.sleep(5)\n",
    "\n",
    "        return bloomberg_ticker, quotes\n",
    "\n",
    "    def download_all(self, ticker_map, eodhd_api_key, date_from=None):\n",
    "        tickers = pd.Series(ticker_map.index).sample(frac=1).unique().tolist()\n",
    "        print(f\"download_all, tickers:{len(tickers)}\")\n",
    "\n",
    "        all_quotes = []\n",
    "\n",
    "        with futures.ThreadPoolExecutor(self.max_workers) as executor:\n",
    "            _futures = []\n",
    "            for ticker in tqdm(tickers):\n",
    "                _futures.append(\n",
    "                    executor.submit(\n",
    "                        self.download_one,\n",
    "                        bloomberg_ticker=ticker,\n",
    "                        map=ticker_map,\n",
    "                        eodhd_api_key=eodhd_api_key,\n",
    "                        date_from=date_from,\n",
    "                    )\n",
    "                )\n",
    "\n",
    "            print(f\"download_all, futures:{len(_futures)}\")\n",
    "            for future in tqdm(futures.as_completed(_futures), total=len(tickers)):\n",
    "                bloomberg_ticker, quotes = future.result()\n",
    "                if quotes is not None:\n",
    "                    quotes[\"bloomberg_ticker\"] = bloomberg_ticker\n",
    "                    all_quotes.append(quotes)\n",
    "\n",
    "        return all_quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_wrong_rows(df):\n",
    "    df = df[df[\"open\"] > 0]\n",
    "    df = df[df[\"high\"] > 0]\n",
    "    df = df[df[\"low\"] > 0]\n",
    "    df = df[df[\"close\"] > 0]\n",
    "    df = df[df[\"adjusted_close\"] > 0]\n",
    "    df = df[df[\"volume\"] > 0]\n",
    "    return df\n",
    "\n",
    "def re_adjust_ohlc(df):\n",
    "    ratio = df[\"close\"] / df[\"adjusted_close\"]\n",
    "    df[\"open\"] = df[\"open\"] / ratio\n",
    "    df[\"high\"] = df[\"high\"] / ratio\n",
    "    df[\"low\"] = df[\"low\"] / ratio\n",
    "    df[\"close\"] = df[\"close\"] / ratio\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_daily_data(data_dir:str, daily_data_dir: str):\n",
    "    # read the latest date\n",
    "    latest_date = get_latest_date(daily_data_dir)\n",
    "    print(f\"Latest date: {latest_date}\")\n",
    "\n",
    "    # download data from the latest date\n",
    "    downloader = StockDataDownloader(data_dir=data_dir, max_workers=16)\n",
    "\n",
    "    ticker_map = pd.read_csv(\"data/eodhd-map.csv\").set_index(\"bloomberg_ticker\")\n",
    "    eodhd_api_key = os.environ[\"EODHD_API_KEY\"]\n",
    "    all_quotes = downloader.download_all(\n",
    "       ticker_map, eodhd_api_key, date_from=latest_date\n",
    "    )\n",
    "\n",
    "    # save all quotes\n",
    "    all_quotes = pd.concat(all_quotes)\n",
    "    all_quotes = remove_wrong_rows(all_quotes)\n",
    "    all_quotes = re_adjust_ohlc(all_quotes)\n",
    "    save_in_folders(all_quotes, daily_data_dir)\n",
    "    gc.collect()\n",
    "\n",
    "update_daily_data(DATA_DIR, DAILY_DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
