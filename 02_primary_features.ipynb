{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "import cudf\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "from src.data_utils import load_recent_data_from_file, save_daily_data, save_in_folders, get_latest_date\n",
    "from src.config import DAILY_DATA_DIR, DATA_DIR, DAILY_PRIMARY_FEATURES_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'src.data_utils' from '/mnt/d/nmr/signals_prod/src/data_utils.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reload modules\n",
    "import importlib\n",
    "import src.data_utils\n",
    "importlib.reload(src.data_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42528901 entries, 42579060 to 1709\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Dtype         \n",
      "---  ------            -----         \n",
      " 0   date              datetime64[ns]\n",
      " 1   open              float16       \n",
      " 2   high              float16       \n",
      " 3   low               float16       \n",
      " 4   close             float16       \n",
      " 5   adjusted_close    float16       \n",
      " 6   volume            float64       \n",
      " 7   data_provider     object        \n",
      " 8   bloomberg_ticker  object        \n",
      " 9   dividend_amount   float16       \n",
      " 10  split_ratio       float16       \n",
      " 11  date_str          object        \n",
      " 12  split_factor      object        \n",
      "dtypes: datetime64[ns](1), float16(7), float64(1), object(4)\n",
      "memory usage: 2.8+ GB\n"
     ]
    }
   ],
   "source": [
    "recent_data = load_recent_data_from_file(DAILY_DATA_DIR, n_days=-1).reset_index().sort_values(\n",
    "    by=[\"bloomberg_ticker\", \"date\"]\n",
    ")\n",
    "\n",
    "recent_data[\n",
    "    [\"open\", \"close\", \"high\", \"low\", \"adjusted_close\", \"dividend_amount\", \"split_ratio\"]\n",
    "] = recent_data[\n",
    "    [\"open\", \"close\", \"high\", \"low\", \"adjusted_close\", \"dividend_amount\", \"split_ratio\"]\n",
    "].astype(\n",
    "    \"float16\"\n",
    ")\n",
    "\n",
    "# filter out tickers with less than 100 days of data\n",
    "recent_data = recent_data.groupby(\"bloomberg_ticker\").filter(lambda x: len(x) > 100)\n",
    "recent_data = recent_data.groupby(\"date\").filter(lambda x: len(x) > 500)\n",
    "gc.collect()\n",
    "\n",
    "recent_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_moving_average(df, window):\n",
    "    res = df[\"close\"].rolling(window).mean()\n",
    "    res.name = f\"sma_{window}\"\n",
    "    return res\n",
    "\n",
    "\n",
    "def exponential_moving_average(df, window):\n",
    "    cum_sum = df[\"close\"].rolling(window).sum()\n",
    "    cum_count = df[\"close\"].rolling(window).count()\n",
    "    ema = cum_sum / cum_count\n",
    "    ema.name = f\"ema_{window}\"\n",
    "    return ema\n",
    "\n",
    "\n",
    "def bollinger_bands(df, window):\n",
    "    sma = simple_moving_average(df, window)\n",
    "    std = df[\"close\"].rolling(window).std()\n",
    "    upper = sma + 2 * std\n",
    "    lower = sma - 2 * std\n",
    "    upper.name = f\"bbupper_{window}\"\n",
    "    lower.name = f\"bblower_{window}\"\n",
    "    return upper, lower\n",
    "\n",
    "\n",
    "def rsi(df, window):\n",
    "    delta = df[\"close\"].diff()\n",
    "    up_days = delta.copy()\n",
    "    up_days[delta <= 0] = 0.0\n",
    "    down_days = abs(delta.copy())\n",
    "    down_days[delta > 0] = 0.0\n",
    "    RS_up = up_days.rolling(window).mean()\n",
    "    RS_down = down_days.rolling(window).mean()\n",
    "    rsi = 100 - 100 / (1 + RS_up / RS_down)\n",
    "    rsi.name = f\"rsi_{window}\"\n",
    "    return rsi\n",
    "\n",
    "\n",
    "def macd(df, window_fast, window_slow):\n",
    "    ema_fast = exponential_moving_average(df, window_fast)\n",
    "    ema_slow = exponential_moving_average(df, window_slow)\n",
    "    macd = ema_fast - ema_slow\n",
    "    macd.name = f\"macd_{window_fast}_{window_slow}\"\n",
    "    return macd\n",
    "\n",
    "\n",
    "# ATR\n",
    "def average_true_range(df, window):\n",
    "    tr = df[[\"high\", \"low\", \"close\"]].max(axis=1) - df[[\"high\", \"low\", \"close\"]].min(\n",
    "        axis=1\n",
    "    )\n",
    "    atr = tr.rolling(window).mean()\n",
    "    atr.name = f\"atr_{window}\"\n",
    "    return atr\n",
    "\n",
    "\n",
    "function_to_window: dict = {\n",
    "    simple_moving_average: [5, 10, 20, 50, 100, 200],\n",
    "    exponential_moving_average: [5, 10, 20, 50, 100, 200],\n",
    "    bollinger_bands: [5, 10, 20, 50, 100, 200],\n",
    "    rsi: [5, 10, 20, 50, 100, 200],\n",
    "    average_true_range: [5, 10, 20, 50, 100, 200],\n",
    "    macd: [(12, 26), (20, 50)],\n",
    "}\n",
    "\n",
    "\n",
    "def compute_features(df):\n",
    "    features = []\n",
    "    for func, windows in function_to_window.items():\n",
    "        for window in windows:\n",
    "            # pass windows as a tuple if the function takes more than one window\n",
    "            if isinstance(window, tuple):\n",
    "                _feat = func(df, *window)\n",
    "            else:\n",
    "                _feat = func(df, window)\n",
    "\n",
    "            if isinstance(_feat, tuple):\n",
    "                features.extend(_feat)\n",
    "            else:\n",
    "                features.append(_feat)\n",
    "\n",
    "    # print type of features\n",
    "    cated = cudf.concat(features, axis=1).astype(\"float32\").add_prefix(\"feature_1_\")\n",
    "    return cated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [02:20<00:00, 11.73s/it]\n"
     ]
    }
   ],
   "source": [
    "tickers_list = recent_data[\"bloomberg_ticker\"].unique().tolist()\n",
    "\n",
    "# iterate over ticker chunks in 500\n",
    "res = []\n",
    "for i in tqdm(range(0, len(tickers_list), 1000)):\n",
    "    tickers = tickers_list[i : i + 1000]\n",
    "    #print(tickers)\n",
    "    tickers_data = recent_data[recent_data[\"bloomberg_ticker\"].isin(tickers)]\n",
    "    \n",
    "    _df_gpu = cudf.from_pandas(tickers_data)\n",
    "    _res = compute_features(_df_gpu)\n",
    "    _res = _res.to_pandas().astype(\"float16\")\n",
    "    _res[\"date\"] = _df_gpu[\"date\"].to_pandas()\n",
    "    _res[\"bloomberg_ticker\"] = _df_gpu[\"bloomberg_ticker\"].to_pandas()\n",
    "    _res[\"close\"] = _df_gpu[\"close\"].to_pandas()\n",
    "    _res[\"volume\"] = _df_gpu[\"volume\"].to_pandas()\n",
    "    _res[\"open\"] = _df_gpu[\"open\"].to_pandas()\n",
    "    _res[\"high\"] = _df_gpu[\"high\"].to_pandas()\n",
    "    _res[\"low\"] = _df_gpu[\"low\"].to_pandas()\n",
    "\n",
    "\n",
    "    res.append(_res)\n",
    "\n",
    "    del _df_gpu, _res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "res = pd.concat(res, axis=0)\n",
    "res = res.dropna(axis=0)\n",
    "\n",
    "# convert float 16 to float 32 in a loop\n",
    "for col in res.columns:\n",
    "    if res[col].dtype == \"float16\":\n",
    "        res[col] = res[col].astype(\"float32\")\n",
    "    gc.collect()\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "del recent_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:04<00:00, 23.41it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.25it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 73.56it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 99.34it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.88it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.79it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.60it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 111.32it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 108.54it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 95.13it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 102.17it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 87.02it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.21it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.84it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 97.65it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 100.03it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 113.31it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 81.70it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 59.76it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 83.18it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.40it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 63.89it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.07it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 67.02it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 61.84it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.41it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.59it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.77it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.75it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 84.91it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 60.22it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 63.75it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.00it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 89.87it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.27it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 91.13it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 89.55it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 89.28it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 82.64it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.02it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 90.75it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.86it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 83.28it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.58it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.11it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 94.53it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 88.58it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 85.50it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.13it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.88it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 64.03it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 93.42it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.51it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 70.26it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.97it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 68.03it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 66.83it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 67.96it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 65.17it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 62.97it/s]\n",
      "100%|██████████| 100/100 [00:01<00:00, 63.66it/s]\n",
      "100%|██████████| 17/17 [00:00<00:00, 1424.55it/s]\n",
      "100%|██████████| 62/62 [03:38<00:00,  3.53s/it]\n"
     ]
    }
   ],
   "source": [
    "# loop over all unique dates in chunks of 100; save each chunk to a separate file\n",
    "res[\"date_str\"] = res[\"date\"].dt.strftime(\"%Y-%m-%d\")\n",
    "dates = res[\"date_str\"].unique()\n",
    "\n",
    "for i in tqdm(range(0, len(dates), 100)):\n",
    "    # use save_in_folders function to save each chunk to a separate folder\n",
    "    _tmp = res[res[\"date_str\"].isin(dates[i : i + 100])]\n",
    "    save_in_folders(_tmp, DAILY_PRIMARY_FEATURES_DIR)\n",
    "\n",
    "    del _tmp\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
