{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import gc\n",
    "import multiprocessing\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Union, List, Tuple, Optional, Dict, Any\n",
    "import cudf\n",
    "import numba\n",
    "from numba import cuda\n",
    "\n",
    "import itertools\n",
    "\n",
    "from src.data_utils import (\n",
    "    load_recent_data_from_file,\n",
    "    save_daily_data,\n",
    "    save_in_folders,\n",
    "    get_latest_date,\n",
    "    read_available_dates,\n",
    ")\n",
    "from src.config import DAILY_DATA_DIR, DATA_DIR, DAILY_PRIMARY_FEATURES_DIR\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combination_ratio(df: Union[pd.DataFrame, cudf.DataFrame], feature_prefix: str):\n",
    "    # fetch feature_name and its combination ratio\n",
    "\n",
    "    feature_cols = [f for f in df.columns if feature_prefix in f]\n",
    "    feature_pairs = itertools.combinations(feature_cols, 2)\n",
    "\n",
    "    _feature_list = []\n",
    "    for _f1, _f2 in feature_pairs:\n",
    "        _feature_type = _f1.split(\"_\")[2]  # sma, ema, macd, rsi, etc.\n",
    "        _f1_window_size = _f1.split(\"_\")[-1]  # window size 1\n",
    "        _f2_window_size = _f2.split(\"_\")[-1]  # window size 2\n",
    "\n",
    "        _res = 1 - (df[_f2] / df[_f1])\n",
    "        _res.name = (\n",
    "            f\"feature_2_ratio_{_feature_type}_{_f1_window_size}_{_f2_window_size}\"\n",
    "        )\n",
    "\n",
    "        _feature_list.append(_res)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    # ratio with close price for each feature\n",
    "    for _f in feature_cols:\n",
    "        _feature_type = _f.split(\"_\")[2]\n",
    "        _f_window_size = _f.split(\"_\")[-1]\n",
    "\n",
    "        _res = 1 - (df[\"close\"] / df[_f])\n",
    "        _res.name = f\"feature_2_ratio_{_feature_type}_{_f_window_size}_close\"\n",
    "\n",
    "        _feature_list.append(_res)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    _cated_res = pd.concat(_feature_list, axis=1).astype(\"float32\")\n",
    "\n",
    "    del _feature_list\n",
    "    gc.collect()\n",
    "\n",
    "    return _cated_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_prefixes = [\n",
    "    \"feature_1_sma\",\n",
    "    \"feature_1_ema\",\n",
    "    \"feature_1_rsi\",\n",
    "]\n",
    "\n",
    "def calculate_all_secondary_features(\n",
    "    df: Union[pd.DataFrame, cudf.DataFrame], feature_prefixes: List[str]\n",
    "):\n",
    "    _all_features = []\n",
    "    for feature_prefix in feature_prefixes:\n",
    "        _features = [f for f in df.columns if feature_prefix in f]\n",
    "        _res = get_combination_ratio(df.loc[:, _features + [\"close\"]], feature_prefix)\n",
    "        _all_features.append(_res)\n",
    "        gc.collect()\n",
    "\n",
    "    _all_features = pd.concat(_all_features, axis=1).astype(\"float32\")\n",
    "    return _all_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FROM_SCRATCH = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:41<00:00, 23.87it/s]\n",
      " 14%|█▍        | 1/7 [01:12<07:15, 72.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:36<00:00, 27.10it/s]\n",
      " 29%|██▊       | 2/7 [02:24<06:00, 72.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:39<00:00, 25.41it/s]\n",
      " 43%|████▎     | 3/7 [03:41<04:56, 74.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:38<00:00, 25.95it/s]\n",
      " 57%|█████▋    | 4/7 [05:03<03:51, 77.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:38<00:00, 26.29it/s]\n",
      " 71%|███████▏  | 5/7 [06:25<02:38, 79.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:38<00:00, 26.18it/s]\n",
      " 86%|████████▌ | 6/7 [07:47<01:20, 80.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 117/117 [00:03<00:00, 31.89it/s]\n",
      "100%|██████████| 7/7 [08:02<00:00, 68.92s/it]\n"
     ]
    }
   ],
   "source": [
    "dates = read_available_dates(DAILY_PRIMARY_FEATURES_DIR)\n",
    "\n",
    "start_index = len(dates) - 1000 if not FROM_SCRATCH else 0\n",
    "\n",
    "# iterate over all dates in chunks of 200\n",
    "for i in tqdm(range(start_index, len(dates), 1000)):\n",
    "    print(i)\n",
    "    _df = load_recent_data_from_file(\n",
    "        DAILY_PRIMARY_FEATURES_DIR,\n",
    "        n_days=1000,\n",
    "        ascending=True,\n",
    "        offset=i,\n",
    "        dtype=\"float32\",\n",
    "    )\n",
    "\n",
    "    feat_cols = [f for f in _df if \"feature_\" in f]\n",
    "\n",
    "    _res = calculate_all_secondary_features(_df, feature_prefixes).astype(\"float32\")\n",
    "\n",
    "    # combine primary and secondary featuers\n",
    "    _res = pd.concat([_df, _res], axis=1)\n",
    "    _res = _res.replace([np.inf, -np.inf], np.nan)\n",
    "    _res = _res.dropna(axis=0)\n",
    "\n",
    "    assert _res.isna().mean().sort_values(ascending=False).max() < 0.1, \"too many NaN values found\"\n",
    "    save_in_folders(_res, os.path.join(DATA_DIR, \"03_secondary_features\"))\n",
    "\n",
    "    #del _df, _res\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
